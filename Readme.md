# Принципы разложения данных по слоям Stage, ODS и Datamart

## 1. Stage 

### Назначение
Слой `Stage` — начальный этап, куда данные загружаются из источников "как есть" с минимальной или нулевой трансформацией, сохраняя исходный формат и структуру. К данным добавляются технические поля, такие как `load_date` (дата загрузки), для отслеживания источника и времени загрузки. Иногда проводится проверка целостности и удаление дублей. Основная цель — снизить нагрузку на источники, контролировать качество данных и добавлять метаданные.

## 2. Слой ODS (Operational Data Store)

### Назначение
Слой `ODS` — промежуточный уровень между `Stage` и DWH, предназначенный для интеграции и оперативного хранения данных. Данные собираются из `Stage`, очищаются, нормализуются и структурируются для оперативной аналитики. Поддерживается историчность (например, SCD), обеспечивая единый источник правды для детального анализа. ODS оптимизирован для частых обновлений и предоставляет данные в реальном или почти реальном времени.

## 3. Слой Datamart

### Назначение
Слой `Datamart` — конечный уровень, где данные подготавливаются для аналитики и отчётности. Витрины данных оптимизированы для конкретных бизнес-задач (например, анализ продаж, расчёт долей отгрузки).

### Принципы
- **Агрегация и оптимизация**: Данные из `ODS` агрегируются, денормализуются или преобразуются в структуры, удобные для аналитики (например, звёздная или снежинковая схема).
- **Фокус на бизнес-потребности**: Каждая витрина создаётся для конкретной задачи, например, `fact_Продажи` для анализа транзакций или `dm_Доли_Отгрузки` для расчёта долей.
- **Факты и измерения**: 
  - **Факты**: Таблицы с числовыми показателями (например, сумма продаж в `fact_Продажи`).
  - **Измерения**: Справочники, описывающие контекст (например, партнёры, регионы).
- **Производительность**: Используются индексы, партиционирование и денормализация для ускорения запросов.




# ETL
  Хотел сделать интересный пет проект из тестового задания, развернув всю инфру в docker compose, наполнив тестовыми данными source_db и пройдя все этапы вплоть до построения отчетов в PowerBI. Но к сожалению я не учел, что на домашнем маке с m1 процессором развертывание софта компаниии Microsoft может занять сильно больше времени, чем на других архитектурах. В общем спустя "несколько десятков" часов мытарств с архитектурой понял, что поднимать PBI через эмуляцию Windows я не успеваю. В общем docker compose, airflow и тестовые датасеты я прикладываю тоже. Даг и скрипты создания витрин находятся в директориях dags, scripts.